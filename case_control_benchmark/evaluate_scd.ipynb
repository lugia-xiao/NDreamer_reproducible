{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a506f1-ce75-4aac-b284-0f3b3915b42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to determine R library path: Command '('/vast/palmer/apps/avx2/software/R/4.3.2-foss-2022b-patched/lib64/R/bin/Rscript', '-e', 'cat(Sys.getenv(\"LD_LIBRARY_PATH\"))')' returned non-zero exit status 127.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_HOME is already set to: /vast/palmer/apps/avx2/software/R/4.3.2-foss-2022b-patched/lib64/R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/wang_zuoheng/xx244/Ndreamer/case_control_benchmark/metrics.py:29: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  anndata2ri.activate()\n",
      "/home/xx244/.conda/envs/benchmark/lib/python3.11/site-packages/rpy2/robjects/pandas2ri.py:368: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n",
      "/home/xx244/.conda/envs/benchmark/lib/python3.11/site-packages/rpy2/robjects/numpy2ri.py:241: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  warnings.warn('The global conversion available with activate() '\n"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import gc\n",
    "import sys\n",
    "import cellanova as cnova\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sea\n",
    "\n",
    "from metrics import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68bfd066-887e-4d29-b42d-0cd0fa9827db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_proportion_matrix(df):\n",
    "    \"\"\"\n",
    "    Calculates the mean proportion for each combination of condition and neighbor\n",
    "    and summarizes the result in a square matrix dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe with columns ['condition', 'neighbor', 'proportion'].\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A square matrix dataframe where rows represent 'condition' and columns represent 'neighbor'.\n",
    "    \"\"\"\n",
    "    # Use a pivot table to calculate the mean proportions\n",
    "    mean_matrix = df.pivot_table(\n",
    "        index='condition',\n",
    "        columns='neighbor',\n",
    "        values='proportion',\n",
    "        aggfunc='mean',\n",
    "        fill_value=0  # Replace NaN with 0 if there are missing combinations\n",
    "    )\n",
    "\n",
    "    return mean_matrix\n",
    "\n",
    "def calculate_rowwise_correlation(adata1, adata2, batch_key=\"batch_all_with_condition\"):\n",
    "    # Ensure the obs index and batch_key match\n",
    "    #assert np.sum(adata1.obs[\"batch_all_with_condition\"]!=adata2.obs[\"batch_all_with_condition\"])==0, \"obs indices do not match between the two AnnData objects\"\n",
    "    assert batch_key in adata1.obs.columns, f\"{batch_key} not found in adata1.obs\"\n",
    "    assert batch_key in adata2.obs.columns, f\"{batch_key} not found in adata2.obs\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Iterate through unique batches\n",
    "    unique_batches = adata1.obs[batch_key].unique()\n",
    "    for batch in unique_batches:\n",
    "        # Subset the data for the current batch\n",
    "        batch_mask = adata1.obs[batch_key] == batch\n",
    "        data1 = adata1[batch_mask].X\n",
    "        data2 = adata2[batch_mask].X\n",
    "        \n",
    "        barcodes=adata1[batch_mask].obs_names.tolist()\n",
    "\n",
    "        # Ensure the data is in dense format if sparse\n",
    "        if not isinstance(data1, np.ndarray):\n",
    "            data1 = data1.toarray()\n",
    "        if not isinstance(data2, np.ndarray):\n",
    "            data2 = data2.toarray()\n",
    "\n",
    "        # Compute correlation for each row\n",
    "        for i in range(data1.shape[0]):\n",
    "            row_corr = np.corrcoef(data1[i, :], data2[i, :])[0, 1]\n",
    "            mse=np.mean(np.square(data1[i, :]-data2[i, :]))\n",
    "            results.append({\"correlation\": row_corr, batch_key: batch, \"barcode\":barcodes[i], \"mse\":mse})\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    result_df = pd.DataFrame(results)\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def extract_de_results(adata, batch_key, cell_type_key, key_added=\"DE_wilcoxon\", min_cells=30):\n",
    "    results = []\n",
    "\n",
    "    # Iterate through unique batches\n",
    "    unique_batches = adata.obs[batch_key].unique()\n",
    "    for batch in unique_batches:\n",
    "        # Subset the AnnData for the current batch\n",
    "        adata_batch = adata[adata.obs[batch_key] == batch]\n",
    "        \n",
    "        # Filter out cell types with fewer than `min_cells` cells\n",
    "        cell_counts = adata_batch.obs[cell_type_key].value_counts()\n",
    "        valid_cell_types = cell_counts[cell_counts >= min_cells].index\n",
    "        \n",
    "        # Subset the AnnData object to only include valid cell types\n",
    "        adata_batch = adata_batch[adata_batch.obs[cell_type_key].isin(valid_cell_types)]\n",
    "        \n",
    "        # Skip the batch if there are no valid cell types\n",
    "        if adata_batch.shape[0] == 0 or len(valid_cell_types) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Perform DE analysis\n",
    "        sc.tl.rank_genes_groups(adata_batch, groupby=cell_type_key, method='wilcoxon', key_added=key_added, use_raw=False)\n",
    "        \n",
    "        # Extract DE results for each valid cell type\n",
    "        for cell_type in valid_cell_types:\n",
    "            # Extract adjusted p-values and gene names\n",
    "            gene_names = adata_batch.uns[key_added]['names'][cell_type]\n",
    "            pvals_adj = adata_batch.uns[key_added]['pvals_adj'][cell_type]\n",
    "            \n",
    "            # Create a dictionary for the current cell type and batch\n",
    "            row_data = {\n",
    "                \"cell_type_key\": cell_type,\n",
    "                \"batch_all_with_condition\": batch,\n",
    "            }\n",
    "            # Add adjusted p-values for each gene as separate columns\n",
    "            row_data.update({gene: pval for gene, pval in zip(gene_names, pvals_adj)})\n",
    "            results.append(row_data)\n",
    "    \n",
    "    # Convert results to a DataFrame\n",
    "    result_df = pd.DataFrame(results)\n",
    "    return result_df\n",
    "    \n",
    "def evaluate_scd(adata, cell_type_key, batch_key, condition_key, dataset_name):\n",
    "    adata.raw=None\n",
    "    print(\"adata preprocessing...\")\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "    if isinstance(batch_key, str):\n",
    "       batch_key = [batch_key]\n",
    "\n",
    "    batch_all = []\n",
    "    for i in range(adata.shape[0]):\n",
    "        tmp = \"__\".join([adata.obs[batch_keyj][i] for batch_keyj in batch_key])\n",
    "        batch_all.append(tmp)\n",
    "    batch_all = np.array(batch_all)\n",
    "    adata.obs[\"batch_all\"]=batch_all\n",
    "    adata.obs[\"batch_all\"] = adata.obs[\"batch_all\"].astype(\"category\")\n",
    "    print(\"batch_all\",np.unique(batch_all))\n",
    "\n",
    "    batch_all_with_condition = []\n",
    "    for i in range(adata.shape[0]):\n",
    "        tmp = \"__\".join([adata.obs[batch_keyj][i] for batch_keyj in batch_key])\n",
    "        tmp = tmp + \"__\" + adata.obs[condition_key][i]\n",
    "        batch_all_with_condition.append(tmp)\n",
    "    batch_all_with_condition = np.array(batch_all_with_condition)\n",
    "    adata.obs[\"batch_all_with_condition\"] = batch_all_with_condition\n",
    "    adata.obs[\"batch_all_with_condition\"] = adata.obs[\"batch_all_with_condition\"].astype(\"category\")\n",
    "    print(\"batch_all_with_condition\", np.unique(batch_all_with_condition))\n",
    "\n",
    "    batch_key.append(\"batch_all_with_condition\")\n",
    "    batch_key.append(\"batch_all\")\n",
    "\n",
    "    main_effect_adata = ad.AnnData(adata.obsm['main_effect'], dtype=np.float32)\n",
    "    #main_effect_adata.var_names = adata.var_names\n",
    "    main_effect_adata.obs = adata.obs.copy()\n",
    "\n",
    "    integrated = ad.AnnData(adata.layers['denoised'], dtype=np.float32)\n",
    "    integrated.obs = adata.obs.copy()\n",
    "    integrated.var_names = adata.var_names\n",
    "    print(\"Finish preprocessing\")\n",
    "    \n",
    "    print(\"Calculating global distortion...\")\n",
    "    df_global_correlation=calculate_rowwise_correlation(adata, integrated)\n",
    "    df_global_correlation.to_csv(\"./scd/\"+dataset_name+\"_global_correlation.csv\")\n",
    "    print(\"Finish\")\n",
    "\n",
    "    print(\"Evaluate gene-level signal distortion\")\n",
    "    if True:#dataset_name!=\"mouse\":\n",
    "        real_data_DE = extract_de_results(adata=adata, batch_key=\"batch_all_with_condition\", cell_type_key=cell_type_key,key_added=\"DE_wilcoxon\")\n",
    "        denoised_DE = extract_de_results(adata=integrated, batch_key=\"batch_all_with_condition\", cell_type_key=cell_type_key,key_added=\"DE_wilcoxon\")\n",
    "        real_data_DE.to_csv(\"./scd/\"+dataset_name+\"_real_DE.csv\")\n",
    "        denoised_DE.to_csv(\"./scd/\"+dataset_name+\"_denoised_DE.csv\")\n",
    "    print(\"Finish\")\n",
    "    \n",
    "    print(\"Plot of main effect:\")\n",
    "    if main_effect_adata.shape[1] > 60:\n",
    "        sc.pp.pca(main_effect_adata)\n",
    "    else:\n",
    "        main_effect_adata.obsm['X_pca']=main_effect_adata.X.copy()\n",
    "    sc.pp.neighbors(main_effect_adata, n_neighbors=15)\n",
    "    sc.tl.umap(main_effect_adata)\n",
    "    sc.pl.umap(main_effect_adata, color=[cell_type_key, condition_key] + batch_key, ncols=1)\n",
    "    \n",
    "    print(\"Plot of denoised expression\")\n",
    "    sc.pp.pca(integrated)\n",
    "    sc.pp.neighbors(integrated, n_neighbors=15)\n",
    "    sc.tl.umap(integrated)\n",
    "    sc.pl.umap(integrated, color=[cell_type_key, condition_key] + batch_key, ncols=1)\n",
    "\n",
    "    print(\"Finish adata preprocessing\",\"=\"*20)\n",
    "\n",
    "    print(\"Batch-related mixing performance evaluation for main effect:\")\n",
    "    for batch_keyi in batch_key:\n",
    "        print(batch_keyi)\n",
    "        import rpy2.robjects as robjects\n",
    "        import anndata2ri\n",
    "        anndata2ri.activate()\n",
    "        # Add your library path\n",
    "        library_path = \"/gpfs/gibbs/project/wang_zuoheng/xx244/R/4.3/\"  # Replace with the actual path\n",
    "        # Update R's library paths\n",
    "        robjects.r(f'.libPaths(c(\"{library_path}\", .libPaths()))')\n",
    "        # Verify the updated library paths\n",
    "        print(robjects.r('.libPaths()'))\n",
    "        calculate_metrics(main_effect_adata, batch_key=batch_keyi,\n",
    "                          celltype_key=cell_type_key, all=True, n_neighbors=15)\n",
    "        print(\"=\" * 20)\n",
    "\n",
    "    print(\"Within each unique condition, evaluate the batch effect of denoised data\")\n",
    "    unique_conditions=np.unique(np.array(integrated.obs[condition_key]))\n",
    "    for conditioni in unique_conditions:\n",
    "        print(\"Within each unique condition, evaluate the batch effect of denoised data\")\n",
    "        print(\"Now evaluating\",conditioni)\n",
    "        integratedi=integrated[integrated.obs[condition_key]==conditioni].copy()\n",
    "        import rpy2.robjects as robjects\n",
    "        import anndata2ri\n",
    "        anndata2ri.activate()\n",
    "        # Add your library path\n",
    "        library_path = \"/gpfs/gibbs/project/wang_zuoheng/xx244/R/4.3/\"  # Replace with the actual path\n",
    "        # Update R's library paths\n",
    "        robjects.r(f'.libPaths(c(\"{library_path}\", .libPaths()))')\n",
    "        # Verify the updated library paths\n",
    "        print(robjects.r('.libPaths()'))\n",
    "        calculate_metrics(integratedi, batch_key=\"batch_all\",\n",
    "                          celltype_key=cell_type_key, all=True, n_neighbors=15)\n",
    "        print(\"*\"*20)\n",
    "    \n",
    "    print(\"Batch-related mixing performance evaluation for main effect:\")\n",
    "    for batch_keyi in batch_key:\n",
    "        print(\"Batch-related mixing performance evaluation for main effect:\")\n",
    "        print(batch_keyi)\n",
    "        import rpy2.robjects as robjects\n",
    "        import anndata2ri\n",
    "        anndata2ri.activate()\n",
    "        # Add your library path\n",
    "        library_path = \"/gpfs/gibbs/project/wang_zuoheng/xx244/R/4.3/\"  # Replace with the actual path\n",
    "        # Update R's library paths\n",
    "        robjects.r(f'.libPaths(c(\"{library_path}\", .libPaths()))')\n",
    "        # Verify the updated library paths\n",
    "        print(robjects.r('.libPaths()'))\n",
    "        calculate_metrics(main_effect_adata, batch_key=batch_keyi,\n",
    "                          celltype_key=cell_type_key, all=True, n_neighbors=15)\n",
    "        print(\"=\" * 20)\n",
    "    \n",
    "    res = cnova.utils.calc_oobNN(integrated, batch_key=\"batch_all_with_condition\", condition_key=condition_key)\n",
    "    df = res.obsm['knn_prop']\n",
    "    df['condition'] = res.obs[condition_key]\n",
    "    df.index.name = \"index\"\n",
    "\n",
    "    df = df.reset_index()\n",
    "    df = pd.melt(df, id_vars=['index', 'condition'], var_name='neighbor', value_name='proportion')\n",
    "    df = df.rename(columns={'index': 'obs_name'})\n",
    "    df.to_csv(\"./scd/\" + dataset_name + \"_oobNN.csv\")\n",
    "\n",
    "    g = sea.FacetGrid(df, col='neighbor', hue='condition')\n",
    "    g.map(sea.kdeplot, 'proportion', bw_adjust=2, alpha=1)\n",
    "    g.set(xlabel='NN proportion', ylabel='Density')\n",
    "    g.add_legend()\n",
    "    plt.suptitle('scd integration')\n",
    "    sea.set_style('white')\n",
    "    plt.show()\n",
    "\n",
    "    df_summarize=calculate_mean_proportion_matrix(df)\n",
    "    print(df_summarize)\n",
    "    df_summarize.to_csv(\"./scd/\"+dataset_name+\"_summary.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486ed194-1aba-483b-baf2-d07ab9e95247",
   "metadata": {},
   "source": [
    "# Type 1 diabetes\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE148073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b334d74-78af-417d-89ac-d0043c1fe999",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad(\"./scd/t1d_latent.h5ad\")\n",
    "evaluate_scd(adata=adata,cell_type_key=\"cell_type\",batch_key=\"donor_id\",\n",
    "                   condition_key=\"disease_state\",dataset_name=\"t1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7053ef13-429d-4315-b4f2-fabbb3d42a80",
   "metadata": {},
   "source": [
    "# Human kidney multiomics atlas\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE211785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b59077-2190-47ae-b29e-c00fa32337eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad(\"./scd/kidney_latent.h5ad\")\n",
    "evaluate_scd(adata=adata,cell_type_key='Cluster_Idents',batch_key=['sample','tech'],\n",
    "                   condition_key=\"Status\",dataset_name=\"kidney\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2748f76-7bce-445d-9d54-57e831d24931",
   "metadata": {},
   "source": [
    "# Mouse radiation experiment dataset\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE280883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80fbd9e-92c9-442d-b0be-578a9939c45e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad(\"./scd/mouse_latent.h5ad\")\n",
    "print(adata)\n",
    "adata.obs['orig_ident']=adata.obs['orig.ident'].copy()\n",
    "evaluate_scd(adata=adata,cell_type_key='compartment',batch_key=['orig_ident',\"replicate\",\"source\"],\n",
    "                   condition_key=\"sample\",dataset_name=\"mouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719b33a-108e-42c3-acd7-a77379ceb04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
